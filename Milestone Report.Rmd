
library(knitr)
opts_knit$set(root.dir = "C:/Users/jrtho/Documents/Coursera/Capstone/Assignment 1/final/en_US")
library(tm)
library(stringr)
library(readr)
library(ngram)

# Read the data

twit <- readLines("en_US.twitter.txt")
blog <- readLines("en_US.blogs.txt")
news <- readLines("en_US.news.txt")

# Sample and cleaning the data

# Sample the data 

set.seed(98765)
sample <- c(sample(twit, length(twit) * 0.001),
            sample(blog, length(blog) * 0.001),
            sample(news, length(news) * 0.001))

# Load the data as a corpus

corpus <- Corpus(VectorSource(sample))

# Text transformation

# Replacing "/", "@" and "|" with space:

toSpace <- content_transformer(function (x , pattern ) gsub(pattern, " ", x))
corpus <- tm_map(corpus, toSpace, "/")
corpus <- tm_map(corpus, toSpace, "@")
corpus <- tm_map(corpus, toSpace, "\\|")

# Cleaning the data

# Convert the text to lower case
docs <- tm_map(docs, content_transformer(tolower))
# Remove numbers
docs <- tm_map(docs, removeNumbers)
# Remove english common stopwords
docs <- tm_map(docs, removeWords, stopwords("english"))
# Remove punctuations
docs <- tm_map(docs, removePunctuation)
# Eliminate extra white spaces
docs <- tm_map(docs, stripWhitespace)

# Convert the corpus to a data frame

corpusdf <- data.frame(text = unlist(sapply(corpus, '[', 'content')), stringsAsFactors = F)
